VERSATILE PROGRAMMING LANGUAGE 2

Key principles:
- Uninitialized data (variables/arrays on stack, on heap, in registers, in comms buffers/queues, anywhere) must not be allowed UNLESS explicitly asked for (e.g. as an optimization when the programmer knows it'll definitely get overwritten before use - this is often very important in time-critical use cases).
- Several (conceptually) atomic initializations must be supported : default-construction (default ctor of the type runs), zero-value-construction (in case it differes from the default construction), and user-specified construction (via constructor or external compatible init-procedure). The last option must be leaving the data uninitialized, see above.
- Initialization must be protected from concurrent access (critical section or other means). Static analysis + runtime check/locking!
- Concurrency and parallel processing must be part of both the language and the standard library.
- Concurrency and parallelism must aim at correctness and convenience first and only then try to squeeze out the last 10% of performance.
- Concurrency and parallelism must encourage and/or require algorithm construction which is safe or at least not very unsafe. Therefore, low-level, overly manual, unchecked (neither statically nor at runtime) constructs must be left out of the core language and only accessible (if at all!) via extern sections / unsafe sections. Higher-level, human-traceable parallel constructs with useful support from the compiler and runtime can do the job in most cases. Human time waste and buggy operation are way more expensive than a few % of unused/unoptimized CPU time and/or a few KB or MB of RAM.
- The language and runtime must prefer composability at various levels and in many places. Things which were not designed to compose should be given less prominence and discouraged (e.g. some ways of doing inheritance-based OOP, threading vs tasking, and others).
- The language must prefer regularity unless good reasons exist not to for a particular feature.
- The language must have several profiles of clearly defined purpose and availability of language constructs and runtime facilities in each. Basically, these are a subset of (System size: Tiny|Small|Medium|Large) X (Realtime requirements: Hard|Soft|None) :
-- Tiny Hard-real-time Systems Profile (microcontrollers with ~1-2 KB RAM, 10s of KB to 100s of KB of flash storage, 8-bit - e.g. AVR8.) with only the most essential features + permission to use a few low-level constructs which are otherwise banned in high profiles. Very Simple Tasking!
-- Small Hard-real-time Systems Profile (16-bit but mostly 32-bit microcontrollers, 100s of KB of RAM to 10s of MB, several MB to 10s of MB of flash storage, possibly and RTOS). More language constructs and runtime facilities, but still deterministic execution. OS interfacing. Simple Tasking.
-- Small Soft-realtime Systems Profile (e.g. mobile phones and some non-critical control systems which control processes which are relatively slow by nature).
-- Mid-size Application Systems Profile (essentially stuff like tablets and ordinary apps on powerful smartphones). No big deal if something isn't realtime but simply fast enough - which means a lot of language features and runtime support become available and even mandatory. Tasking is not restricted to simple predictable subsets.
-- Mid-size Soft-realtime Systems Profile (Some industrial monitoring and dashboard applications, many multimedia applications, some small internet or LAN servers, many OS components (kernelspace or userspace)).
-- Mid-size Hard-Realtime Systems Profile (Typical industrial control and monitoring applications, some middleware servers, many OS components (kernelspace or userspace - perhaps entire micro/hybrid kernels).
-- Large Application Systems Profile (Desktop-class machines, laptops, servers).
-- Large Soft-realtime Systems Profile (Servers for some time-critical purposes, some industrial monitoring and dashboard applications, time-critical complex midleware, time-critical distributed systems, OS kernels of monolithic/hybrid architecture etc.)
-- Large Hard-realtime Systems Profile (OS kernels of monolithic/hybrid architecture, highly time-critical complex middleware, highly time-critical distributed systems).

- The language and runtime must encourage and require clear, explicit specification of intentions; where defaults and automation are used, they must follow the principle of least surprise. This doesn't mean extreme verbosity of code, but definitely means NO terse and cryptic code. Searchability of the source code and traceability (not only by compiler but also by humans) of things must be a priority, too. In this respect:
-- The type system must forbid implicit conversions even if they are non-narrowing, even inside arithmetic expressions. Some conversions may be needed when dealing with enumerations, constants, booleans and conditionals, and references, but in general C-like or C++-like conversions are not to be performed implicitly.
-- The type system must forbid arbitrary casting. Const-ness, volatility, atomicity, and the undecorated type itself must be respected even across code coming from different places and authors; casting in the sense of reinterpreting is to be permitted only in a few cases where it is truly needed. Violating types out of convenience or for minor performance gains is not good for reliability, safety, and architecture.
-- The type system must  always make a clear distinction between conversion (e.g. int->double or the other way round) and reinterpretation (kind of like C++ reinterpret_cast<>). Conversion modifiers must be provided for some conversions, mostly those involving numerical types, to control how things like overflows and roundoff are handled. Leaving everything to be implementation defined or undefined isn't useful nor safe! When the hardware can't provide good enough guarantees, strict beahviour must be emulated via libraries or inline sequences of instructions (like Java strict FP, Boost lexical_cast<>, etc.).
-- The language must not be a slippery slope of value, reference, parameter-passing conventions, etc. It must always be absolutely clear what a variable or constant is and how it is being treated. Java isn't doing it right, C++ isn't at all (it confuses and intertwines things which should be set apart : values, lvalue and rvalue references, pointers), and functional languages usually overcook things. The language must be designed to allow for extracting reasonable performance without resorting to tricks, and must be intuitively programmable.
-- The language must pay due attention to the fundamental differences between pure value types, pure references, and reference-containing types.
-- The language must forbid unrestricted pointer arithmetic, prevent random garbage in reference, and proactively fight dangling references (make them impossible in many cases and expose them otherwise). Of course, low-level code does reguire some freedom, so limited forms of potentially dangerous operations must be allowed, but not everywhere, and not in all application profiles. Unsafe sections, annotations, etc.
-- The language must forbid keeping and creating direct references to parts of objects which are not independently-existing, proper, subobjects. E.g. descriptors, accessors, iterators, slices, and so on must provide sub-object access services. Those must always keep a reference to the entire object, and use other means to refer to its parts.
-- The above 4-5 requirements make garbage collection and compile-time proofs and optimizations feasible and efficient.
-- The language must provide a rich set of reference types, suitable for different purposes and circumstances. The language and runtime must provide support for limited manual reference management, for both synchronous and asynchronous finalization/destruction, and for good management and reclamation of non-memory resources. Different application profiles must support different resource management modes and techniques. In general, tiny devices can't be treated the same as large applications, and different approaches to resource management are suitable for hard-, soft-, and non-realtime applications. For some of them highly determinstic refcounting is the logical choice, for others tracing collectors and prgramming simplicity are the best; some need to take care of cyclic structures and some don't, and so on. It's not at all good or necessary to expect to provide a single and equally apt interface to resource acquisition and disposal for all application profiles. So yes, some code will need to have specialized versions.
-- The language must have a type system which is flexible, understandable, and layered. Not every application profile has to or should or physically can support all of the layers.
--- The types must be divided into 3 general categories :
---- Pure value types : these contain no references and are trivially memory-copiable.
---- References : these are references to objects; there are several flavours; specific compile-time and/or run-time care is required to handle them, depending on the flavour.
---- Reference-containing types : these are the most complicated in terms of handling.
--- Arrays != references; they don't decay to pointers; they are objects which always know their size. Whether and where the size is stored at runtime depends on the flavour. Access via indexing, iterators, slices, etc - but not pointer arithmetic.
--- Errors != exceptions. Exceptions are exceptional events -- assume any of them can happen any time. When you really expect it, it's a good old error and not a true exception, no matter whether represented by a return code, errno, or something thrown (up). Checking for errors is what should be enforced rather than for truly exceptional events. "How can you expect it if you have no idea it is to be expected?"
--- Functions != procedures. Sorry, but C-family languages (including Java) mixed them up. Function <=> take read-only parameters and compute a result and error status without changing any state; procedure <=> take all sorts of parameters of which usually there's at least one writable (but not always!), do something to the state of those writable parameters and/or to the program and/or system state (e.g. system calls to OS), and return an error status but not anything else. Any subroutine call returns an error code, always (if not specified by programmer, defaults to SUCCESS). Error status != boolean value, probably an integer or integer-based enumeration (or references? That's the most flexible thing! Of course, it must be light on performance - a NULL reference probably is good enough. Like in the Go language "err".)
--- Parameters to functions : always Read-only (IN); parameters to procedures : IN, OUT (write-only, no reading allowed), INOUT (read-write). Parameters quite close to C++ lvalue references (and rvalue ones sometimes). ??/ by reference or by value? explict copy/deepcopy/?. OUT and INOUT always passed by (internal) reference (object has to be modified); IN passed by value if a pure value type (primitive numerical/logical/bool type, char type, or struct type) and by reference if a reference-containing type???
--- Only concurrency-enabled references are allowed to cross concurrent task boundaries; only concurrency-enabled objects (wrapped or otherwise) are allowed to be pointed to by concurrency references.
--- Concurrency : Favor higher-level constructs where possible, especially at larger application profiles. Reasoning about and checking real-time properties is also much more feasible with structured higher-level constructs.
---- Container-based data parallelism: parallel for loops, with manual or automatic partitioning. Several flavours:
----- 
---- Task-based parallelism: several flavours :
---- Only objects which are marked for concurrent use may be used in concurrent contexts; read-only (const or immutable) objects are also OK, with some precautions. Objects marked as concurrent are given locks or atomic instruction treatment by the compiler and runtime. No need to do manual locking. Recursive locks most of the time + lock elision. Reader-writer locks specifiable. Both modifying and non-modifying function/method calls and operations require synchronization to ensure consistent state is written and consistent state is read.
---- "Const" is for constants (strictly compile-time computable stuff! Similar to C++11 "constexpr"); "immutable" is a superset of const which includes stuff initialized at run-time but not modifiable once fully initialized.
---- Const stuff is concurrent-safe. Immutable stuff is safe, too, but only after initialization is complete. This is enforced.
---- Objects of any type can be declared const or immutable.
---- Entire types can include immutable qualifiers. Any object of such a type is immutable, exactly as if explicitly declared as immutable.
---- Immutable objects require no locking or atomics once fully constructed.
---- Strings are, by default, immutable.
---- A third concept exists : that of frozen objects, which can be made read-only on a temporary basis and then reverted to writable state. (Un)Freezing is done with "freeze"/"unfreeze" keywords. Both are idempotent operations. Freezing/unfreezing can succeed only on objects which are not part of multiple access contexts at the moment (comple time error or runtime error if not so). This basically means that if an object is potentially accessible from more than 1 place (variable, concurrent task, etc.), it cannot be frozen (since not all clients will know about that). Read-only access is illegal after a transition frozen->unfrozen; ??? Freeze queues???
---- Types can be qualified as "noconcurrent" to forbid being used in concurrent contexts.
---- Functions, the way they are defined, don't have any state (no static variables allowed!). Use procedures wrapping functions instead.
---- Types can use type-wide static storage/state; for types marked for concurrent use, locking/atomics are automatically applied to it. Types not marked for concurrent use which contain type-wide static fields are forbidden in concurrent contexts, as even if the access to an object is synchronized, there may be many different objects of the type which simultaneously access the type-wide state.
---- For types which contain no references (i.e. pure value types), it is sufficient to lock the object. For references themselves and reference-containing types, recursive traversal and locking along the reference graph is needed in the general case. Circular refs need to be handled as well. It can all get heavy and surprising (e.g. hard-to-spot deadlocks). For these reasons, reference-containing types are treated the following way: if the type or variable is custom_concurrent, then its custom_concurrent_graph_lock() method is called, asssuming the programmer(s) will do the right thing further on. Else, it the object is locked itself and the referred to objects are looked at : if they are all custom_concurrent, they are all locked in one go (i.e. atomically),  ???
---- Global storage/state which is mutable is automatically wrapped in locks. Every access to such objects uses the locks implicitly. The locks are recursive. Reader-writer specifiable. Actually, global state is always contained within a special "Global" module.
--- Per-Module storage/state : static storage visible only to entities within a module; concurrency protected. If the compiler can prove that no concurrent access can ever happen in the program, locks should be omitted (save writeable data section space) and elided (save locking/unlocking overhead).
--- When specilized concurrency-safe data structures and algorithms are available, for example queues using atomics, the compiler can be told that it is safe to not provide the default concurrency protection. A type, free-standing function or procedure, or a variable can be marked "custom_concurrent". No locking etc. is auto-generated then, but any arguments in calls to methods/functions/procedures are required to be of either "concurrent" or "custom_concurrent" qualification. A "custom_concurrent" variable may, for example, hold a frequently updated counter which is allowed to have missed updates due to non-atomic concurrent increment operations.
---- Static immutable storage/state needs no concurrency protection.
---- The programmer can specify a bunch of independent calls as executable cocnurrently/in parallel. There are several flavours:
----- "auto_concurrent_dynamic" : The compiler and runtime are jointly given the responsibility to decide if the calls can indeed be executed concurrently. The compiler prints out a notification to the programmer.
----- "auto_concurrent_static" : The compiler performs the decision only based on static analysis. It prints out a notification to the programmer.
----- "force_concurrent" : The programmer makes the sole decision, manually.
----- To specify the desired level of parallelism : "parallel=<NumOfThreads>", default value is "=auto", i.e. the runtime decides.
At runtime, the calls which are independent are wrapped into tasks which are put into the same task-of-tasks; the one(s) which are found to depend on other task(s) are put into another task-of-tasks, and the execution dependency graph is adjusted accordingly.

--- Tasking, threading, etc. : Concurrency is based on tasking which is based on several things:
---- Execution dependency graph : one per Execution domain.
---- Execution domain : now that's interesting. Execution domains are somewhat like OS processes (and can be implemented as such) : there is a certain degree of memory/resource isolation. Namely: An execution domain does not implicitly share memory with other execution domains; various levels of decsriptor sharing can be specified; all communication occurs via some (virtual) IPC mechanism. The language and runtime provide virtual communication channels/message queues for this + a control API. Commands are sometimes also queued, to ensure e.g. safe destruction of the context inside the domain. Forced quit also exists. Flow of control is based on tasking primitives and messaging - there is no direct calling; error status and computation results are returned via message-based task packaging mechanisms, and exceptions/critical signals are injected as exceptions into the context of the task on whose behalf other tasks are being executed. Non-critical signals are wrapped into messages and queued. Execution domains may or may not have various resource limits, and, depending on the platform, may or may not support various scheduling modes (preemtive, cooperative, etc.).
---- Tasks which are very closely connected (share memory implicitly and more) are only executable in the same execution domain. Every task which is not so tightly coupled with other tasks can be launched into any execution domain, subject to various additional constraints.
---- Every application starts with one primary execution domain, with 2 default tasks : the primaryED._init_main task and the primaryED._main_main task (the latter depends on the former, of course).
---- Tasks can be of several types, according to logical role and privileges:
----- The _main_main task of the primary ED has total control over every other task in the ED and over all secondary EDs and the individual tasks in them.
----- The program ends (logically) when the _main_main_ task of the primary ED ends (via return or (propagated) exception). The program ends (physically, from the OS point of view) when the _main_finalization task of the primary ED ends (via return or locally-encountered fatal exception).
----- Each single ED has similar tasks, with similar purposes. Secondary domains may have automatically-generated default intit, setup, and finalization tasks, or may be launched with user-supplied custom ones. The default ones basically serve as slave servers to the primary ED.
----- The main tasks of each secondary domain are allowed to exert total control over tasks within that ED.

-- Classical tons-of-locks approach is not considered for usability reasons. Instead, configurable Software Tranactional Memory is used, along with message-passing-oriented + strict ownership.
--- Concurrent access correctness issues are actually ownership issues. When something that doesn't really (explictly) own an object or entire object (sub)graph tries to access it behind the owner's (or multiple owners'!) back(s), bad stuff happens. If the owner is one, and if it knows it is the sole owner AND everyone else knows that too, the best approach is "ask it to do something on your behalf and let it manage if, how, when" -- i.e., send a request but don't touch the owned thing yourself. If the service can't be performed, a reply can say it can't, provide reasons, etc. Queueing may be used, which may actually lead to high efficiency due to batching optimization opportunities. It is still possible to have entity A ask B for something, which B can't provide before A has provided B with something else, so deadlocks are still possible (and indirect/trnsitive ones too). But, with a message-oriented approach, the parties are not so closely tied, so they may be much more adaptive. Once a reply message is received saying "can't satisfy request right now", the requester can back off for some time, or retry immediately, retry at most N times, or keep retrying indefinitely - so, deadlock doesn't happen as nothing is actually being locked - what can happen is at most livelock. Some sort of management/scheduling engine can be used to mitigate such problems by arbitration, ordering, etc.
--- Using shared ownership (e.g. via some C++-like shared_ptr which does refcounting, or via non-refcounting shared reference) and concurrent access is exactly a violation of the single ownership principle. If a thing isn't visible from more than 1 place, there's no confusion of formal ownership, effective ownership, ownership duration, etc. Unique_ptr style is actually much better for safe sharing, as it enforces single ownership. For example, if a task A needs to spawn off another task B to process (modify!) some data A owns, the following should happen: 1. A transfers ownership to B; 2. A sleeps or does something else while letting B run to completion; 3. B transfers ownership back to A before death; 4. A now has the exclusive ownership again and so may do whatever it wants with the object. If at any time A or B attempts any (even read-only) access to the data while it's not currently in "legal possession" of it, a fatal runtime error will occur. This approach requires only atomic transfer of ownership (one or 2 pointer-sized locations)(+perhaps a barrier), and absolutely no locking or atomics for actually accessing the data once ownership transfer is complete. Finer-grained, highly-concurrent access to e.g. writeable arrays can be provided by creating non-overlapping accessor objects such as slices, each of which provides unique ownership of part of the underlying array. For linked (non-contiguous) data structures, things will often be more complex, but the approach of asking the container/data structure to provide safe partial accessors and oversee the access is still valid.
For more complex or simply more general access patterns, a gather/scatter approach is applicable, i.e. something which involves what is essentially transactions. 2-Phase Commit and so on.
Gather:
For every R in Resources
	send message to R that we want it to quiesce its state;
	if reply is OK then gather Value(R) and proceed with next R else cancel all reservations and free Values so far and retry loop;
If all reservations are OK, we have gathered all data, then proceed working on the copies...
When (and if) time comes to write anything back, commit or abort...

Actually, there can be several scenarios:
1. Only reads are in the transaction : this means all reservations can be released after the gather stage.
2. Only writes -||- : this means there's only a scatter stage.
3. A mix of reads and writes -||- : this means both stages are needed.

If there is long-running processing between gather and scatter in 3., support should be provided for another transaction preempting the long-running one. Read ops of the original data will not cause abort, but write will (as data will have changed in the meantime).
Transaction ordering and prioritization may very much alleviate non-determinism concerns.

When CPUs become able to lock multiple cache lines, it will all be so much easier...



-- Support for region-based allocation. Named regions.

