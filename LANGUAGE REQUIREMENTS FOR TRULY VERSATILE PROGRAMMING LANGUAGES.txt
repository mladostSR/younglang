LANGUAGE REQUIREMENTS FOR TRULY VERSATILE PROGRAMMING LANGUAGES

0. The language and to some extent the toolchain and runtime must be very portable at the core, with additional special functionality being well-specified and present on all conforming platforms. The language must be defined in a not-as-huge-as-C++ standard and possess official extensive conformance tests. Anyone anywhere must be allowed completely unrestricted and royalty-free access to the entire documentation and tests, and anyone must be allowed to implement the language, toolchain, and runtime without any restrictions and requirements - other than that the language as a "trademark" cannot be used unless the product conforms fully to the mentioned language specification. 
1. The language must be multi-paradigm, to allow selecting the most natural approach(es) to particular tasks. True, deep mixing of paradigms must be both allowed and natural.
2. The language must favor and even sometimes force the "Say it once and once only!" principle. Therefore, it must be very good at code resue at all levels: from ad-hoc code reuse to large-sscale module reuse. The language must disallow repeating oneself whenever that is possible/feasible for the toolchain.
3. The language must provide for several levels of modularity, at different levels of grain. They must interact well and be as simple as possible without blocking advanced usage scenarios.
4. The language must, in general, favor composable constructs over non-composable ones. It must make predictable/human-understandable/machine-understandable composition syntax, semantics, techniques easy to use and anything else - hard or impossible to use.
5. The language must be high, medium, and low-level at the same time, but with a reasonably clear distinction. Why make such a mix of levels of abstraction? Well, it's simply better to have a single though mult-faceted language that is designed as a coherent whole rather than a bunch of languages which need different toolchains, bridges, interops, whatever. And, low level is sometimes needed, even in the midst of higher-level stuff.
6. The language must make it easy to write correct code (even provably correct code) and hard to write incorrect or dubious code.
7. The language must be able to detect most common programming errors during compile time and if not possible/practical - during runtime. Constructs which enable/aid in static and dynamic verification/self-testing must be an intrinsic part of the language.
8. The language must have a clear distinction between errors which are expected and unexpected conditions/errors - and not throw around exceptions all the time.
9. Handling of some error/exceptional conditions must be enforced by the compiler, but not in an extremely tedious and counter-productive way (as in Java, but not only). It should be clear what is what. In case of severe errors, the language must provide adequate means for putting the system into a "failsafe" state, logging/announcing the condition, and quitting/auto-restarting the program/system/machine if desired.
10. Concurrency and parallelism must be in the design from the start.
11. Concurrency and parallelism must be easy to use for the several most typical cases in which they are natural and beneficial. Users must have concurrency primitives available in the core language, and not need to waste time and brain power fiddling with a gazillion of libraries (unless they want/need to, of course).
12. Concurreny must first aim at logical clarity and verifiability, and then at those last 10% of performance.
13. Concurrency must pay a lot of attention to scalability. Scalability must be automatic whenever possible (i.e. concurrent operations on data must be auto-split to take adavntage of the number of ccores on the machine that's running them).
14. Concurrency must be task-based and agent-based, but allow low-level thread manipulation when absolutely necessary (via a dedicated, "unsafe" interface, which compilers and verifiers are aware of).
14. The language must be rich in its core, and not offload half of the useful/interesting/cool stuff to linraries of mutually inconsistent design/interfaces.
15. The language must have a rich standard library, but with modular runtime to allow low size overhead and use on resource-constrained devices.
16. The language must be as future-proof as possible, i.e. avoid design decisions which are clearly getting obsolete even now or which are likely to become showstoppers due to interference with other language features.
17. The language must have a multi-paradigm runtime : it must be very tunable with respect to resource use, key algorithms and techniques, OS/external interfaces, etc. Specifically, it must offer the choice between at least:
17.1. Concurrent and non-concurrent, generational and non-generational (for small address space systems) completely automatic mark-sweep garbage collection (which deals with graph cycles with no user intervention), several reference-counting GCs which do require user intervention for dealing with cycles but are generally of smaller and more predictable latency and memory footprint, a hybrid refcount+backup marksweep GC, completely manual memory management mode, and any GC mode + manual hinting/requests to the GC.
17.2. The threading/tasking approaches to map the language concurrency constructs to the concrete execution environment (OS, CPU(s), ccNUMA, non-ccNUMA/clusters/grids, heterogeneous computing (e.g. GPGPU+CPU like OpenCL, CUDA) ).
17.3. What runtime checks the user wishes to be performed : e.g. array bounds checking, pointer/references checks, I/O checks, data checksumming, concurrency correctness checks, etc. A certain set of not-too-expensive checks must always be performed, while others may be turned off after the software has been tested well. The user must be able to specify on a per-object/variable/module/function/task basis what checks they wish to be performed (e.g. be strict about attackable web-browser parts, but don't slow down video/graphics decoding modules).

18. The language and runtime must encourage and sometimes enforce policy-based design and operation. The ways to specify policies for common purposes must be standardized, lightweight, and non-verbose.

19. On the low-level side of things, the language must be able to provide support for:
19.1. Convenient and efficient manipulation of bit vectors (of both fixed and arbitrary length) - both of single bits and bit ranges.
19.2. Convenient and efficient manipulation of compact data structures, i.e. C/C++ bitfields, but with better control over several aspects.
19.3. Convenient and efficient manipulation of byte vectors/arrays.
19.4. Convenient and efficient manipulation of both ASCII (1-byte) and multibyte character sequences/strings. Includes support for string interning, delayed(lazy) concatenation, regular expression processing, and both mutable and immutable string types.
19.5. Range-restricted types (numerical) and size-restricted types (collections, strings, buffers, ...) which have the compiler auto-generate code for runtime checks on every assignment to/modification of an instance of such a type; constraint violation => runtime error/exception.


20. On the high-level side of things, the language must be able to provide support for:
20.1.1. Shared-nothing mode of communication between tasks/coroutines - via channels.
20.1.2. Shared-something -||- - via channels + *explicitly* captured closures/pointers/references of shared state, with *explicit* consistent RW specifications.
20.1.3. Old-style shared-memory communication via mutexes and co. This should be generally deprecated and available only in a "system programming" mode.
20.2.1. Clear RW/const-ness syntax+semantics, and consistency enforecement across different pieces of code (even across modules). E.g. Casts from const to writable must be *prohibited* and RW attributes of data and code must be part of their mangled signatures always.
20.2.2. Even if a piece data is, in general, writable, a "lock" must be able to be set on it to make it read-only temporarily, e.g. a an object be locked before being passed to other code, and unlocked only after taht only by its owner.
20.3.1. Code annotation with certain classes of parameter constraints.
20.3.2. Code annotation with certain classes of optimization hints to the compiler and/or runtime.
20.3.3. Code annotations with certain classes of invariants/assertions.
20.3.4. Code annotations with certain classes of "intents" and "plans", e.g. regarding interface stability/changes in the foreseeable future. Versioning etc.
20.3.5. Code annotations/comments as feedstock for the documentation generation tools.
21. Data must have enforced clear ownership, and the toolchain must be able to produce ownership reports. Ownership and its transfer must be part of the core language.
22. Interface (API, ABI) stability, optionality, versioning, etc. metadata must be embedded into the object files, libraries, executable programs, and all the necessary intermediate representations of the toolchain and runtime. Anything which is considered unnecessary or private must be strippable from the final executable or library, and/or ignored (not loaded) by the runtime. There must be at least these modes: "strip everything which is not strictly necessary for the correct operation of the program or library", "strip everything which is necessary only for detailed debugging or other development purposes and is not immediately useful for the end user", "strip all debugiing/diagnostic information but leave in the built-in minimal documentation and metadata" ...
22.1. (???) Compatibility and versioning metadata for modules and perhaps smaller units of compilation must be encoded into the output object files/libraries, and optionally into the final executable (not if stripping is requested). Program Text Versions (PTVer) are incremented every time a code unit is changed (ignoring whitespace/pretty-printing differences). Code Versions (CVer) must be incremented every time a change is made to the canonical representation of the source code fragment of the piece of code (i.e. ignoring whitespace and comments which are not machine-readable annotations!, and equivalence after renaming - i.e. consistent variable name changes). Compatibility is automatically set to True if there is no change in the Code Version; if there is such change, the programmer can override in an annotation. When component A calls/embeds/uses component B, if 

22. The language must be designed for at least moderate speed of compilation and linking. It must have a non-convoluted grammar, avoid syntactic redundancies, be concise (=> less to lex and parse, and less to analyze, too). It must avoid copy-pasting of source code text or object code as much as possible, including, but not limited to, #include's (modules are asymptotocally much much faster) and dumb C/C++ style macros (mixins and even function calls are almost always a better alternative). Referencing of code instead of copy-pasting!

23. The language must support comparably well several modes of compilation and execution, which are appropriate for more or less different purposes and environments, applying caching/redundancy elimination and other acceleration techniques where possible:
23.1. "Offline" traditional (like with C/C++) compilation to {rich machine code| lean machine code|rich byte code| lean byte code|another language like C, C++, Java, Javascript, Ada, etc.}
23.2. "Semi-Online" / "Quick Offline" compilation (like with Go, C under TCC) compilation to -||-. This means lowering optimization levels, omitting some compile-time and/or runtime checks, and so on.
23.3. "Online"/ "Incremental" / possibly (but not necessarily!) "Interactive" (ML, Haskell, but even C and C++) compilation and linking, at different levels of granularity:
23.3.1. Statement-level.
23.3.2. Package/module-level.
23.3.3. Patch-level (=> static and dynamic patching!)
The intent is to allow short type-build-run-test-revise cycles via background gradual (incremental) compilation and linking, and to allow immediate feedback to the human. This is very useful for both learning the language and prototyping quickly.
24. The language must be suitable for resonably eficient rich-IDE, lightweight-IDE, and IDE-less coding. It must facilitate code analyzers, structure extractors, rewriters, refactorers. Refactoring and testing (including automatic test-case generation) are a priority!
25. The language must provide good support for non-Latin-derived languages, i.e. internationalization, including multi-lingual software construction. Strings which contain human-readable/human-oriented text must be able to provide and use a consistent tagging mechanism (ISO language codes, codepages, UTF, etc.)
26. There must be reasonable serialization/deserialization/permanentization support - more or less automatic with support for hooking into builtin routines to customize their behaviour. Linked data structures must be part of that. Formats must be space- and parse-efficient. There must be serialization policies/modes which are aimed at the different broad classes of purposes (very permanent storage in human-readable form - some markup format like XML or other alternatives; semi-permanent binary storage; transient quick binary for e.g. RPC or LPC or other IPC; others if necessary )
27. Reflection/Program Introspection must be available at several levels of completeness, and the user must be able to tune it or even switch it off. The user must be able to e.g. prevent 3rd parties from poking around compiled object code for purposes of reverse engineering, sabotage, data theft, and so on. Code access checking and integrity self-checks must be part of the build toolchain and the runtime. However, things should not just happen behind an unsuspecting end-user's (and programmer's) back, i.e. protected and thus possibly "secretive" code modules must remain identifiable as such even within a final program. Run-time available data must in all cases allow enough information to allow the efficient operation of an exact garbage collector (=> identifiable pointer fields in arbitrary data structures, lookup via bitmap or else - this shouldn't increase the object code size by much).

28. Type system:
28.1. The language must provide a type system which is not cumbersome, and does not require extreme verbosity.
28.2. The language must provide a flexible enough type system which allows coding in a mix of various paradigms and styles.
28.3. The language must make extensive use of type inference, and allow very short variable/constant declarations, e.g. x:=SOME_VALUE
28.4. The language must allow specifying types explicitly.
28.4. The typing discipline must be somewhat duck-typing-like (ability-based, interface-based) and chooseable : the programmer/system designer must be able to tag a variable/constant as being of a specific fixed type (monomorphic or polymorphic), byt dynamic typing must also be allowed (indeterminate types, expected types, type hinting?). At compile time, a compiler switch must be available to prohibit dynamic typing, polymorphism, etc., thus forbidding anything which is not a 100% staticly typed program if this is deemed beneficial or necessary.
28.5. Types must be quite extensible, i.e. method declarations must be permitted to be added later on, outside the main/initial class definition. The language Go is a good exqample of such approach, and it definitely works well. In order to be more complete and flexible, the language must provide the ability to make a class or free standing function or anything else "final" or "sealed", i.e. make them unmodifiable/constant/unextendable/unoverridable.
28.6. All overriding/overloading must be explicit (somewhat like in the C++11 standard, but not exactly, and also not on a opt-in basis as is there).
29. The language must provide a syntactically simple and uniform way of specifying extended attributes of types/classes, variables, methods and functions, code blocks, statements, etc. Ugly and verbose stuff like __attribute__((something_of_a_long_name(some_obscure_value))) is not the best thing one can do. Why not simply use [], or () constructor syntax and/or "." member selector syntax -- an attribute is a property of an object, after all! E.g. "x.alignment" should make the alignment of anything available, "var x int32 .alignment(16B)" is similar.
30. The language must provide facilities for specifying code sections as real-time (RT attribute), which means the compiler and code analyzers are told to pay special attention. Certain operations can be automatically detected to be strongly inappropriate or potentially inapropriate for time-critical sections, so the compiler is able to flag their use in an RT section as an error or respectively a warning. Also, the GC can be forbidden to run in the most timing-sensitive sections, while allowed to run freely during the rest of the time. Additionally, exception propagation and handling may be modified somewhat for such sections. RT sections may also allow specifying timeouts and timeout handlers, and also influence how tasks are generated and scheduled.
31. The language must provide at least the following control over the GC *and* other "background tasks/activities/actors":
31.1. Hinting them that they should cease activity temporarily until reenabled (cease-reenable points).
31.2. Querying their current state: running, preparing to run, will definitely not run soon, will likely not run soon, will likely run soon, will run after NNN time (if they run under a fixed schedule), etc. (Tricky!!! Scheduling depends on the OS and other processes and services on a system, so this information will usually be more of a hint itself and not a promise.)
31.3. Forcing them to stop "immediately" (i.e. as early as they can assure a consistent memory/IO/program state) and blocking (with timeout!) until they do so. If timeout is violated => timing error/exception.
31.4. Resuming them {hint|command}.
31.5. Whatever else is there.
32. The language must provide a clear, rich, and mandatory error and exception hierarchies. Several modes of error and exception notofications and handling must be allowed: synchronous mode, asynchronous mode (error|messsage => messsage into special message queues), and hybrid mode (?).
33. Message queues and queueing in general must be an important part of the language and core standard library. Channels for inter-task/inter-thread communication are actually a (simplified) kind of mq's.
33.1. Mq's for internal communication (within the address space of the process) : both typed and untyped messages (any data can go in), with capacities specified at creation time  (0=> synchronous communication, >0 => asynchronous, as in the Go language) or left growable.
33.2. Mq's for external communication (usually outside the address of the process, but of course, usable as internal mq's too) : mapping to POSIX realtime mq's, Windows mq's, QNX stuff, etc.
33.4. Mq's which usually/normally to reside on other machines across a network : mapping to AMQP services.
33.5. Encoding control for messages (via channel/mq attributes) and automatic conversion to/from the appropriate formats of message format and/or payload.

34. Runtime system must be highly queriable and monitorable. More than normal C/C++ runtimes are, at least as much as the 8g/5g/6g Go language runtime is, and preferably the way typical Java VMs are. Of course, such functionality must be divided into several levels/tiers, so that users are able to disable what they don't want. A minimum level must always be present to enable painless program construction and operation, depending on platform type (Microcontroller vs. Kiosk vs. ...).

35. The language must provide uncomplicated interoperability with other languages, to the extent reasonable and feasible. The language must be able to call and be called from C and C++, as a bare minimum. It should also support SWIG bridging and should have as a priority interoperability with Ada, Java, Lua, JavaScript, CPython, Jython, JVM languages in general. The language must be able to inline C and C++, as a bare minimum. The inlined/foreign-language code is permitted to be interfaced in any technically and license-compatible way, as long as this does not cause extreme performance overhead or risk likely instability. When there is a way to mix languages cleanly and reliably within the same address space and/or task/thread of execution, this approach should be preffered to alternatives involving external processes and IPC.

36. GUI
37. Network programming
38. Distributed programming and systems
38. TUI
39. WebUI

40. Grammar and lexing : The language must have a (mostly) unambiguous grammar. The grammar and lexemmes must allow for and facilitate simple and efficient searching and navigation of the code; both human and machine readability must be an important design consideration. Source code must be reasonably compact, which means2 things : 1. It must not be overly verbose (i.e. the Java syndrome), but must also discourage/make impossible dense constructs and cryptic idioms. Constructs which are inherently error-prone and complicate both the language design and understanding must be excluded (i.e. the prefix/postfix increment operators in C/C++ which are both statements and value-producing expressions, and which cause evaluation order bugs in function parameters, and which lead to needless idioms like the *p++ = *q++; etc.). Also, obscured copying/assignment/conversion/move/etc. a la C++ is a madness which must and can be avoided (at least to a certain extent). Small amounts of verbosity are better than low clarity and even lower predictability.
Declarations and uses of variables, functions, structured entities (structs, classes, ...), types, operators, etc. must be different enough at the lexical level to allow easy spotting of entities of interest, and also facilitate parsing. Specifically, things must *not* be declared in a form closely matching the way they are used - unlike e.g. function declarations in C/C++. Mutliple choice constructs must be flexible enough to make it worth using them instead of less structured series or nestings of if-statements; compilers should warn about such sequences when they are semantically better expressible via multiple-choice constructs.
The use of the same symbol for many many different purposes must in general be avoided, again for searchability and simplified parsing. E.g. the
<something>
... body ... / ... description ... / ... specification ...
end <the thing>

is much searchable in a sea of curly braces, brackets, "int"S, and other stuff.

In a way, Pascal-related languages, BASICs, Fortran, Python do it better than C-related languages. If everything looks similar, how can one make anything out? The price is slight verbosity, but that's not so bad here.

41. Enumerations : Enumerations are a special kind of constants (grouped typed constants). They must not be treated as simple one-off constants, as this may obscure the fact that they go together in some sense, and, which is important, prevent compiler checks of coverage in conditional/choice statements. Enumerations must be strongly typed (with a few exceptions), of either an explicitly and completely (including width/memory size) specified type, or of an automatic (flexible) type - e.g. an arbitrary-size Integer, Decimal, etc. For cases in which we are not interested in specific details of the encoding of the enumeration, because it is a more or less abstract entity, an abstract type must be used. E.g. Months { Jan, Feb, Mar, ..., Dec} can be encoded (represented) as integer values 0..11 or 1..12, but may also be considered strings "Jan", "Feb", ... . It may also be quite useful to have their durations in days associated closely. Therefore, every enumeration type does and must have several consistently declared representations and attrributes/properties, e.g.
def enumeration Months { Jan, Feb, ..., Dec } //The abstract part of the declaration.
	with interpretations int { 0..11 }, string { ..Names };	// ..Names being 'Jan', 'Feb', etc. - auto-gen by compiler.
	with properties NumOfDays int { 31, 28|29 /*Multi-valued, leap years! */, 31, ... }, //Properties.
		AverageTemperature double { -11.5, -8.3, ... },  // Properties.
		Nice bool { true, false, ... };
	with synonyms { January, February, ..., December }, { JAN, FEB, ..., DEC };
end enumeration

OK, there's the problem of e.g. an int interpretation which counts from 0 and one which counts from 1. How to avoid mixing things up => outright bugs, esp. when combining modules of different origin? One solution is to simply not allow an interpretation of a a certain type to have two versions anywhere in an entire program (and a single module). But then actually it must be about an entire type of types, so conflicts between int32 and int8 or int16 must not occur. This will often less work, but will mean forcing a convention where it may not be the only meaningful one. Also, what would happen if one module (from maker A) uses one interpretation, and another module (from maker B) uses an incompatible interpreration -- and the client need to use the modules together? A better solution than the previous suggestion would be to have the compiler/linker spot the differences and refuse to link them, thus forcing the client to always use a the module name as prefix. But then, how do we know which convention was used for a value coming from somewhere distant and possibly unknown (e.g. from a compact representation saved somewhere on disk)? In general, that can't be solved. For inter-module communication, the only safe thing is to enforce a common (== single) definition of any thing, i.e. add a rule to the language that:
--> Language Rule : If more than 1 module in a program or program system (bunch of consistently interfaced programs, whose final executables before symbol strip must be checked for mutual consistency by the consistency checker tool) use a public entity of the same simple name (unqualified name, i.e. with all qualifiers like module name ignored), then  all publicly visible non-overload definitions (full interfaces) of the various entities must either be exactly the same (after canonicalization : reordering and similar, but *not* renaming of any sort), or it is an error. THIS ACTUALLY ENCOURAGES the application of the SAY IT ONCE AND ONCE ONLY principle!

What about the implementations of same-name entities? Should it be allowed to have more than one version of an algorithm or type/class behaviour sharing a simple name? How to tell if they are the same or not really (that undecidable!) If clients are always required to use module-name qualified name, ambiguity is resolved, but still it may be confusing to a human (who is not familar with potential differences in behaviour, and even produced values => subtle characteristics of the full interface). Consider this:
SoftwareFloatingMath::Sin(x float64) -> float64 vs. <<ImplicitHardwareVersion>>Sin(x float64) -> float64
What do we know about the compatibility? The two versions are interface-compatible (same signature). But what do we know about behaviour like algorithm correctness, precision, speed? Nothing, until we read the actual implementing source code, and possibly not completely even then.
So, what can be done about it? Again, there is no perfect and magic solution, and only an algorithm can describe itself fully (and not a fixed set of compatibility parameters/markers). One thing can, however, be done relatively easily:
--> Language Rule : If entities of the same simple name and exactly matching full interfaces coming from different modules are used within the same program, then the compiler/linker consistency checker must emit "info"-level notifications that "Incompatibilities between entities of the same full interface specification but possibly different subtle internal behaviour may exist ...". These are, by default, not at "error"-level, or "warning"-level, but compiler/linker/checker flags must exist to raise the level. In order to let software engineers approve (or disapprove) particular replacement/adaptation/refinement/porting module substitutions, the language must provide special facilities:
Attaching a pragma to the respective module as a whole or to a single entity in it which says:
"pragma alternative( <TheNameOfAnAlternative>, ...<<more than 1 may exist>>)" and respectively
"pragma no_alternative( ... )"
"pragma no_alternative"	to "forbid" any and all possible alternatives

What if an enumeration is actually a collection of heterogeneous values (ones belonging to different types or even types of types)? This is not efficient or easy when it comes to code generation, but may be useful for flexibility. E.g. an enumeration of errors/exceptions/runtime notifications of very different nature and structures.
Solution:
def multitype enumeration Events { MinorError, SeriousError, UIQuitMessage, OSSignal, HardwareBrokenFatalException, NumericReturnCode }
end enumeration
INCOMPLETE thing above!!!
enumerations of values, of types themselves (and arent types a kind of value themselves?)

To include entire types: "any <<TypeName>>", e.g. "if ( return_value <<equality operator>> any MinorError ) then ..."

variable_or_constant_name.Type always returns the typeid object corresponding to the true (dynamic) type it is holding/referring to.
-||-.StaticType ... the static (i.e. compile-time) typeid.
Typeids are prefixed with their module names, of course.


42. The language must have a flexible, powerful, and understandable type system. Efficient execution and (static) verification require a mostly static typing discipline, human efficiency and verbosity reduction require reasonably powerful automatic deduction of types and type parameterization, and flexibility in many different problem domains requires polymorphism and other forms of semi-dynamic typing; fully dynamic typing is sometimes very useful and elegant (while it remains debatable if it is absolutely necessary at the language level for any particular task).
Types :
--Pure Value types are types whose entire behaviour depends only on the binary data which is contained INSIDE them. The do not hold any sort of reference to anything outside themselves. Value types are simple and fast in that they are compact (no space-taking references/pointers inside them), tracing GCs don't need to scan inside them and ref-counting GCs don't have refcounts to touch inside them, copying and moving is trivial shallow copy (memcpy), and destruction/finalization is either none or if present does not perform any resource cleanup/reclamation. Value types are FORBIDDEN to hold any handles/descriptors/similar to anything.
--Reference-Containing Types, are types which hold one or more references/handles/descriptors to memory, files, operating system objects, runtime system structures, etc. They generally need some kind of destruction/finalization to ensure correct resource management, and some of them may have 2 kinds of copying operations : shallow copy (i.e. verbatim memcpy) and deep copy ( recursive deep copy on anything they refer to). Reference-Containing types are *not* copied by default; instead, references to them are what is copied. In order to achieve this, Reference-Containing Types are normally kept allocated on a heap (which may or may not be the program-wide default heap), unless the compiler can prove that they cannot escape a certain scope and so can be allocated on stack (which will be the case very often!).
--References are types which are that and nothing else : they refer to/link to/point to some object of whatever type. They are handles. They appear as fields only within Reference-Containing types (never within themselves or Pure Value types) and are, of course, what the GC deals with. All file descriptors, message queue descriptors, and anything which is used to identify a resource is kept in them. They generally require destruction/finalization unless NULL. They are of two general semantic kinds : unique and sharing. Unique references cannot be copied but can be transferred to a new owner leaving the old reference in a NULL state which cannot be dereferenced; sharing references are intended for cases where shared ownership is necessary or preferred and are, in a sense, copyable. Ownership from a unique reference can be transferred to a new shared reference by using the unique reference to initialize the sharing one. A unique reference cannot be initialized from a sharing one of refcount != 1, which implies that in case the referred to object is being used under a tracing and not refcounting scheme, it cannot be assigned, as the refcount is unknown then (well, not really, but it's hard to find out efficiently). When unique ref is initialized from a sharing reference, the sharing reference's refcount drops to 0 and the sharing reference becomes NULL (with no finalization to run on it, since it no longer owns anything).
Assignment of references has the meaning of adding one more co-owner and reducing the number of owners of the old referenced object and so works only between sharing references. Otherwise, it's initialization and not assignment. The assignment operator is used only when it's a true assignment. Searchability and analyzability of the text, remember?
A unique reference is default-initialized as NULL. A sharing reference is also default-initialized as NULL.
A unique non-NULL reference can receive transfer from a NULL unique ref. (!!! Be careful what should and shouldn't happen!)
Setting a unique reference to NULL (via transferring from another NULL reference, including the predefined constant nullref) invokes destructor/finalizer, unless the finalization has been explicitly deferred. Setting a sharing reference to NULL or to another non-null reference performs the expected dec/inc operations. In general, whenever any reference *becomes* NULL, it is scheduled for destrcion/finalization (synchronously==immediately or asynchronously if explicitly deferred and/or using a tracing GC).
Dereferencing a NULL reference, no matter unique or sharing, is an error and must be detected by the runtime. NULL checks are performed always, unless the compiler can prove (statically!) a reference cannot ever be NULL in a certain context. Typical such optimizations are checking for NULL on function/procedure/method entry and not doing any checks on it later on in the body of that if the reference is not written to.

-- Primitive i.e. machine non-pointer types are Pure Value Types.
-- Structured types i.e. structS can be either Pure Value Types or Pointer-Containing types. StructS are supposed to be relatively simple (conceptually, not in terms of nesting or number of fields!). StructS provide no inheritance; they are arbitrarily composable within other structs; they can contain references, including references to Class types / Interface types. As structS have no inheritance, they are monomorphic types. StructS cannot implement general Interfaces (but do support Properties, locking, and a few others), and have simple access control : everything in them is public if the struct is itself a public type or public instance (about this in detail see the Access control and restrictions sections!!!).

-- InterfaceS are sets of Methods which are public (about this in detail see the Access control and restrictions sections!!!). They are a fundamental concept so other more complex concepts as that of a class and module are defined using them.
-- State InterfaceS are similar to the behavioural ordinary InterfaceS, but are more about publicly (about this in detail see the Access control and restrictions sections!!!) visible state rather than actions/behaviour. They are sets of Properties (which do not always have to be backed by storage specifically dedicated to them - e.g. a Property is allowed to return computed values backed by no data field, for example a constant value). They are building blocks like InterfaceS.
-- Classes are closer to the C++ concept and to the Java concept, but still they are not exactly like either. First of all, there are several key characteristics:
-- Classes implement general InterfaceS.
-- Classes implement general State InterfaceS.
-- Data (i.e. state) inside classes is always private to the class. Data can be exposed to entities outside the class only through the gateways called Properties.
-- Classes do *not* support inheritance in the traditional sense but are rather Interfaces-oriented. A class is actually a type which provides certain services to other types (and to itself, of course) by performing some processing, backing it with storage it owns and hides, and occasionally provides in a controlled way through its Properties. Intstead of the inheritance in the copy-all-data-and-services way of C++ and Java, these classes are in some way raw materials for code evolution which allows flexible transformations. Classes can be Extended, Reduced, and Amended. Extending a class means retaining all of the internal structure and interfacing of the "base" class, while adding more publicly visible services (and possibly data/state to back them). Reducing a class means narrowing its interfacing (and possibly removing data/state which becomes unnecessary). Amending a class means transforming it in such ways that it is neither a superset nor a subset of the "base". Deep inheritance hierarchies are not the purpose of existence of classes, but rather code evolution (and reuse).
-- Polymorphism is centered around InterfaceS and State InterfaceS. A reference of the type of some (State) Interface is allowed to be attached to anything which implements that (State) Interface. Thus, it's a much more open world than that of strict hierarchies of rigid classes which can only grow fatter. All Methods and Properties behind any (State) Interface use virtual dispatching, subject to devirtualization compiler optimizations.

-- Collection types are a somewhat separate type of types, in that they are not declared as any other type of types. There are several (State) InterfaceS which every collection must implement and several other conditions it must meet; otherwise anything is allowed.
- CollectionS are of several general kinds, depending on basic internal structure, storage allocation patterns, access patterns, and so on.
- When it comes to internal structure, there are array-based containers : ArrayS, ResizableArrays (aka Vectors) and everything based on them (Heaps, ...); there are linked structures : LinkedArrays ( C++ dequeS ), HashMapS, TreeMapS, TreeS, LinkedListS (doubly and singly and circularly and jumplists), and anything built upon them (SetS, MultiSetS, MultiMapS, ...). The distinction between linked and non-linked data structures is important due to the much simpler allocation and memory accesses of non-linked ones and so on their GC/memory management requirements and real-time behaviour.
-- ??? Tuples ??? They are somewhat container-ish, right?
- When it comes to capacity/size, there are compile-time fixed-size containers, containers whose size becomes known at runtime but which do not grow after allocated initially, and then dynamic-size containers which can grow and shrink all the time. These characteristics are again very important for GC/memory management and real-time behaviour.
- When it comes to whether the containers store references to contained objects or the objects themselves (i.e. the matters of ownership and storage both come into play), these are mostly left to the client to control. In general, containers are type-parameterized, which means the client specifies what goes into a container. It is usually not useful to put references to small Pure Value types, and for big objects it is usually the opposite. For compact storage of certain types, container specializations are provided, just as in C++ (and more!).
- Ownership of contained objects : If a container contains objects and not references, it is their SOLE OWNER. If it contains unique references, then the reference is the true owner - so wherever it goes, and whatever it does, the container doesn't care. If the reference is a sharing reference, then things are similar. Upon removal and overwrite, the normal semantics of the smart pointers apply; the container wipes its objects only if it owns them. Otherwise it simply manages itself.
- Linked containers are essentially Reference-Containing types, non-linked containers are Pure Value types. Tuples are structS (everything inside them is visible), while the rest are "devirtualized classES" : they are like classes (supporting abstraction), but have a "devirtualized" type attribute/pragma? . If they need to be Extended, Reduced, or Amended, then this devirtualized attribute is "inherited" (carried over).
- ArrayS always know their size, and are default-initialized by element-wise default initialization, unless one of several other options is specified (see Collection initialization section). An ordinary array is a very simple thing, containing overhead storage only for keeping its size; the storage space is physically inside and not pointed to. Resizable arrays have a little more stuff inside. All array accesses are bounds checked at runtime, unless the compiler can statically prove a particular access or a bunchof them are within bounds. Also, runtime smart checks are possible and considered a strongly desired optimization. The array metadata (size etc.) is spliced at the end of the array, to make the front part appear as a C array for interop.
- ??? StringS come in several flavours, basically depending on whether they are: mutable or immutable, of a specific encoding (ASCII, EBCDIC, wide-character, wide-wide-character, UTF8, UTF16, UTF32), and contiguous or composed of fragments. Strings are based on ByteBufferS + encoding support. String constants are, of course, immutable and interned.
- Slices, iterators, selectors and multiselectors. Fail-fast on concurrent access (a la Java).
- Concurrent collections.
- Concurrent access to variables
- Closures
- Type hierarchy
There is no hierarchy of data as much as there is a hierarchy of (State) InterfaceS and thus services provided by types. The (State) InterfaceS do have a language-defined, strict hierarchy, in order to keep things standardized and as uniform as possible.
The type hierarchy has a single root. It is the Interface {}, which is both a Method Interface and a State Interface. It supports very few Methods and Properties:
Properties:
- SizeOfSelf (the amount of storage in bytes which is occupied by the object itself)
- SizeWithLinked (recursively computes its true dynamic size; this, of course, does *not* include allocation overheads and other such circumstance-dependednt things.
- Type (returns a special TypeDescriptor type -- what that is to be determined later, but must be strictly defined by the language)
- Convert - interface from/to all supported types(.Convert.To<TargetTypeParameter>. / .From<TargetTypeParameter> -- see with what syntax!!! Seems verbose!!!)
- Alignment (read-only)

The hierarchy then continues at its second level:
Type Hierarchy L2 : { PrimitiveType | StructuredType | ClassType }
PrimitiveTypeS have 
StructureTypeS have
ClassTypeS have 
Arrays
Maps
Multimaps
Sets
Multisets
Trees (binary)
Trees (N-ary, N is fixed at compile time)
Trees (N-ary, N is fixed at run time)
Trees (N-ary, N varies dynamically on a per-node basis)

	
43. Allocation and deallocation of memory and other resources :
43.1. The language must provide support for several types/modes of garbage collection. The language must provide support for mixing uses of the several collectors (!!! Tricky).
43.2. The language must provide finalization/destructor support in all GC modes.
43.4. The language must provide, in general, support for both synchronous and asynchronous finalization/destruction. Synchronous destruction/finalization is available with automatically managed scope variables, when doing manual resource management, and and with reference-counting GCs. Asynchronous destruction/finalization is done when using tracing GCs, or when the source code indicates via specific constructs that delayed/combined/bulk freeing/cleaning-up is requested (i.e. resource descriptors are handed over to GC/fin queues).
43.5. destruction/Finalization is guaranteed to run for all "obligatory-finalize" specified objects, for others it is not done if quick shutdown is being done of the program. Of course, if the OS terminates the program or part of it forcefully, the hardware dies, or the program dies, running any cleanup at all is not and cannot be guaranteed.
43.6. The dsign of the language must minimize the need to rely on GCs and decrease the amount of work geenrated for them. Specifically, scope-based storage such as the stack and "Quick Region Storage" are preferred to allocation everything on the heap; objects are *not* allocated on the heap as much as in e.g. Java but instead the C++ way is usually preferred; by default, all references/pointers are scoped, which saves a lot of GC work and obviates the need for many explicit destruction invocations if manual management is being done. Every resource is bound to a scope upon creation/allocation, and must be detached if the need arises to pass it around freely and/or change its ownership. All of this must be relatively simple. Support for concurrent/parallel use must be considered carefully.
43.7. For use in small embedded and real-time profiles in general, purely static allocation must be supported well. This must *not* be limited to globally visible data structures and stack allocation  (and TLS in some cases) only;
the language must allow static allocation of anything which would otherwise be allocated dynamically provided the data structure sizes are known at compile time and/or during program startup and initialization (before entry into the main routine). Visibility and access rules must be as if ordinary dynamic allocation were being used.

e.g.
var x static Array<int32>(1024,1024)

The compiler must provide a flag to forbid any true dynamic allocation (i.e. from a heap after entry to the main routine).

43.8. The language must prevent the typical error of returning a reference/pointer/descriptor object (e.g. array slice)	to an outer scope when the memory of the referenced object is about to go out of scope and be wiped. Explicit taking of the address of such a variable causes migrating it ( memcpy ) to a heap and the orginal object is set to a non-eligible-for-finalization state. ((A la the Go language.) Actually, migration is probably not necessary at all, as anything whose address is explicitly taken can be directly and automatically allocated on a heap.
43.9. The language must not normally require taking an address explicitly in order to pass arguments/parameters around by reference. So many languages do it well without requiring the clumsiness and error-prone style of C. E.g. like with C++ references which are essentially (in normal use at least) non-storable/non-addressable pointer-like things which always point to an exisitng object. However, C++ references are *not* consistently dedicated to parameter passing, and are often confusingly similar to both "real" objects (addressable storage) and pointers (the addresses of that storage). References as things which bind this and that and which require many pages of discussion in standards are a Bad Thing (TM). Fewer ways to do a thing => fewer ways to get it wrong or confuse things. Therefore, autonomous references of C++ style must *not* exist in a clear language, but instead pass-by-reference must be used. The other references in the language must be what in C++ is smart pointers, of several flavors - each suited best for certain uses. Raw pointers must not pervade the language (it's a mess, error-prone, one can almost never be sure they are all being handled safely, and so on); raw *addresses* are only really needed when doing truly low-level stuff, close to the metal/OS of C/C++ origin. MAKE A CLEAR DISTINCTION BETWEEN POINTERS/LANGUAGE-LEVEL REFERENCES and RAW ADDRESSES.
43.10. There must be a clear, safe, sense-making, and single-style way of declaring references/pointers.
43.10.1. They must always, always be initialized to something sensible -- and not contain garbage that happened to occupy the memory. Therefore, they must either be initialized with an object or existing refrence/pointer, or to a NULL state. When they become detached from an object, they must be automatically returned to the NULL state, without dangling. No double frees and such must be possible. When references/pointers are shared between concurrent tasks/threads and/or by different location in the code, they different copies/views must always be in sync, to prevent all "jumps to hyperspace". These safeties do have runtime costs, but are bugs any cheaper? Also, compilers can do most of the optimization work, and do it more reliably than humans -- especially in large code with complex flow.
43.10.1. When doing reference counting, a lot of useless inc/dec pairs can be avoided when the compiler can easily rpove them unnecessary. E.g. passing a variable by reference to code which cannot cause it to escape to other tasks/coroutines/threads needs no inc on entry and dec on return, since they would simply cancel out and the calling routine will anyway have a live reference.




